"""
cloud.py - Sends the direction that the stepper motor should be moving in order to 
           follow the user to the Arduino. The target x-position is determined by 
           detecting the largest face in frame and then tracking that face. If the 
           face cannot be tracked, face detection is used again.

           To run in verbose mode, run with -v flag 
"""

import numpy as np
import cv2
import sys, os, io
import RPi.GPIO as GPIO
from picamera.array import PiRGBArray
from picamera import PiCamera
import time, serial, argparse, struct
from imutils.video import FPS
from imutils.video.pivideostream import PiVideoStream
import imutils


"""
detectFace - Given a frame, uses OpenCV and Haar Cascades to return a bounding box
             around the largest face found. If no face is found, returns None. 
"""
def detectFace(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = faceCascade.detectMultiScale(
        gray,
        scaleFactor=1.4,
        minNeighbors=5,
        minSize=(100,100),
    )
    
    if(verbose): 
        print("Detecting face")
    
    maxArea = 0
    xpos = 0
    ypos = 0 
    width = 0
    height = 0
    
    # Send largest face
    for (x, y, w, h) in faces:
        if w*h > maxArea:
            xpos = int(x)
            ypos = int(y)
            width = int(w)
            height = int(h)
            maxArea = w*h
    
    # Don't detect face that is off screen
    if 0 < maxArea:
        if xpos < 0 or displayWidth <  xpos + width:
            return None 
        if ypos < 0 or displayHeight < ypos + height:
            return None
        bbox = (xpos, ypos, width, height)
        return bbox
    
    return None


"""
updateStepper - Given the current target position (the middle of the 
                detected face) and a margin of error (to prevent the 
                stepper from moving back and forth rapidly), updates
                what direction the stepper motor should be moving. 
                Reads the stepper's position from the arduino, determines
                whether the stepper should change direction, and sends
                the correct new direction if necessary 
"""
def updateStepper(currPos, delta):
    global stepperDirection
    stepperPos = ser.readline()
    ser.flushInput() # Clear input buffer
    print("Message from Arduino: ", stepperPos)
    
    try:
        stepperPos = int(stepperPos)
    except Exception as e:
        print(e)
        return
    
    if abs(stepperPos - currPos) < delta:
        currDirection = 0  # stopped
    elif stepperPos <= currPos:
        currDirection = 1  # moving right
    else: 
        currDirection = 2 # moving left
   
    print("Current Direction: ", currDirection);
    if(currDirection != stepperDirection):
       stepperDirection = currDirection 
       ser.write(struct.pack('>B', currDirection))

# Parse verbose flag
parser = argparse.ArgumentParser()
parser.add_argument("-v", "--verbosity", required=False, action="count", help="Verbose flag")
args = parser.parse_args()
verbose = False

if args.verbosity:
    verbose = True

# Open serial port to connect with Arduino
try: 
    ser = serial.Serial(
        port = '/dev/ttyACM0',
        baudrate = 9600,
        parity=serial.PARITY_NONE,
        stopbits=serial.STOPBITS_ONE,
        bytesize=serial.EIGHTBITS,
        timeout=1
    )
    if not ser.isOpen():
        ser.open()
        time.sleep(1)
    if(verbose):
        print("Connected to Arduino succesfully")
except Exception as e:
    print(e)

 
# Initialize tracker 
trackingFace = 0 # Does not track face to begin with 
trackerType = "CSRT"
if trackerType == 'MOSSE':
    tracker = cv2.TrackerMOSSE_create()
elif trackerType == "CSRT":
    tracker = cv2.TrackerCSRT_create()
elif trackerType == "KCF":
    tracker = cv2.TrackerKFC_create()

# Initialize face detection 
faceCascade = cv2.CascadeClassifier("data/haarcascades/haarcascade_frontalface_alt.xml")

# Set up camera
displayWidth = 960
displayHeight = 560
stream = PiVideoStream((displayWidth, displayHeight), 32).start()
time.sleep(2.0)
fps = FPS().start() # Use threading to increase fps

stepperDirection = 0

# ------------------------ BEGINNING OF MAIN LOOP ----------------------- #
while 1: 
    frame = stream.read()
    
    # Initialize tracker 
    if not trackingFace:
        bbox1 = detectFace(frame)
        if bbox1 is not None: 
            print ("Bbox: ", bbox1)
            tracker.init(frame, bbox1)
            trackingFace = 1

    if trackingFace:
        ok, bbox = tracker.update(frame)
        
        if not ok: 
            trackingFace = 0
            print("ERROR: Not ok"); 
            bbox = bbox1 #Use the bbox generated by the face detector
     
        p1 = (int(bbox[0]), int(bbox[1]))
        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))
        cv2.rectangle(frame, p1, p2, (255,0,0),2,1)
       
        # Draw circle around target x-position
        xpos = int(bbox[0] + bbox[2]/2)
        ypos = int(bbox[1])
        cv2.circle(frame, (xpos, ypos), 10, (0,0, 255), -1) 
         
        # If message received from arduino, update stepper
        if(ser.inWaiting() > 0):
            delta = bbox[2]/4
            updateStepper(xpos, delta)

    cv2.imshow("Tracking", frame) # If running headless, commment out this line
    fps.update()
    
    k = cv2.waitKey(1) & 0xff
    if k == 27:
        break
    elif k == 32:
        print("Reseting")
        trackingFace = 0

ser.close()
cv2.destroyAllWindows()
stream.stop()
